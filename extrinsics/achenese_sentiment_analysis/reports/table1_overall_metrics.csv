variant,variant_name,experiment,weighted_f1,macro_f1,accuracy,roc_auc,cohen_kappa
1,Back-translation baseline,moderate_aug,0.7965588630822209,0.7885198498148753,0.7975,0.9037642867549532,0.6877650142625857
2,Base LLM + Lexicon,real_only,0.7672875035610578,0.7570700903171254,0.765,0.8919850921655857,0.6422659029931688
3,Base LLM + MT,low_aug,0.7823094268915165,0.7697152764316945,0.785,0.9120075870480248,0.6666537462692352
4,In-language LLM (mT5-LR),full_aug,0.796397734786862,0.7875216640398075,0.795,0.9138055014375251,0.6860973672373697
5,Seeds + LLM + Lex,low_aug,0.7735780810769289,0.7628449235839003,0.7725,0.9031732927252026,0.6502690238278248
6,Seeds + LLM + MT,full_aug,0.7832916651613135,0.7756060551320495,0.785,0.9060242836354184,0.6685742913848585
7,V5 + QA,full_aug,0.7797026993713793,0.7776380842817426,0.78,0.9014623658329756,0.6666856049845653
8,V6 + QA,low_aug,0.7843525282143472,0.775527490938578,0.7825,0.9050830671454406,0.6674502608795367
9,V5 + CoT,moderate_aug,0.7859561476483186,0.7791998959258746,0.785,0.8971685315284224,0.6703749484960857
10,V6 + CoT,low_aug,0.8111825384149447,0.8034799325282304,0.81,0.91798263332621,0.7101836139340667
11,V7 + CoT (full Lex path),full_aug,0.7748625631603123,0.7655945150478912,0.775,0.8893156432288708,0.6551691108152378
12,V8 + CoT (full MT path),full_aug,0.8049599427168576,0.7977141298417894,0.805,0.9233093958420796,0.7009833049011903
