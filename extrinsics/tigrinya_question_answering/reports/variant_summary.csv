variant_name,experiment,rank,weighted_f1,macro_f1,accuracy,roc_auc,cohen_kappa
Back-translation baseline,high_aug,best,0.3850940348218025,0.369009393510301,0.3866666666666666,0.5439828683289397,0.1506646971935008
Back-translation baseline,real_only,worst,0.208141312338195,0.1962239647145307,0.208695652173913,0.4660721972705688,-0.0439944134078214
Base LLM + Lexicon,high_aug,best,0.4451233114647748,0.432149919954798,0.44,0.643969052701921,0.2508917954815695
Base LLM + Lexicon,moderate_aug,worst,0.2912599681020734,0.287322235513025,0.3,0.5720217363261094,0.0611587982832618
Base LLM + MT,synthetic_only,best,0.4864450556685584,0.4857585254530165,0.4857142857142857,0.7107210171619293,0.3147518694765465
Base LLM + MT,moderate_aug,worst,0.1932952380952381,0.1921428571428571,0.2,0.5433192376837133,-0.0615711252653927
In-language LLM (mT5-LR),real_only,best,0.4280222609368951,0.4236026422764227,0.4266666666666667,0.6541611282574841,0.2348754448398576
In-language LLM (mT5-LR),synthetic_only,worst,0.2551236494597839,0.2538795518207283,0.2571428571428571,0.5973021354816705,0.0138173936602546
Seeds + LLM + Lex,high_aug,best,0.5164570887107472,0.5151333219625903,0.52,0.7286154259041789,0.3487698986975398
Seeds + LLM + Lex,low_aug,worst,0.1585585585585585,0.1793939393939394,0.1621621621621621,0.3772218540867734,-0.1367690782953416
Seeds + LLM + MT,synthetic_only,best,0.4904201947742389,0.4891347529000477,0.4928571428571429,0.7263079465911686,0.3230727322255516
Seeds + LLM + MT,low_aug,worst,0.2370429252782193,0.2426470588235294,0.2432432432432432,0.4641458541458541,0.0123927550047663
V5 + QA,high_aug,best,0.5243971565158005,0.4120471689327621,0.5066666666666667,0.6772593176602443,0.2967562088190572
V5 + QA,low_aug,worst,0.2669511616880038,0.2850250626566415,0.2702702702702703,0.4919480161415644,0.0215475024485799
V6 + QA,real_only,best,0.6116752136752137,0.605520990447461,0.6133333333333333,0.8118970986929422,0.4821428571428571
V6 + QA,low_aug,worst,0.1975955888999367,0.1906354515050167,0.2162162162162162,0.5383158508158508,-0.0468292682926829
V5 + CoT,high_aug,best,0.4949557109557109,0.4888111888111888,0.4933333333333333,0.7226444176075658,0.3212669683257918
V5 + CoT,low_aug,worst,0.1524550568668215,0.1285350678733031,0.1351351351351351,0.3548097388722389,-0.1483996120271582
V6 + CoT,real_only,best,0.5281495405179616,0.4915079365079365,0.5131578947368421,0.6721190458506635,0.3461985584747732
V6 + CoT,low_aug,worst,0.1536798336798336,0.1835897435897436,0.1621621621621621,0.4385550167457601,-0.1367690782953419
V7 + CoT (full Lex path),real_only,best,0.4932962962962963,0.3881944444444444,0.4666666666666667,0.6647728397853537,0.2276004119464469
V7 + CoT (full Lex path),low_aug,worst,0.3082989004041635,0.3180085630743525,0.3243243243243243,0.5357353518643841,0.1198858230256898
V8 + CoT (full MT path),high_aug,best,0.523671497584541,0.3318840579710145,0.48,0.6979910351794127,0.1901993355481728
V8 + CoT (full MT path),low_aug,worst,0.1544791544791544,0.1544011544011544,0.1621621621621621,0.4206932852094142,-0.1201171875
